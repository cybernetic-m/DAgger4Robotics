{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "jMyeRyJsr0VH",
   "metadata": {
    "id": "jMyeRyJsr0VH"
   },
   "source": [
    "In this notebook you can train an expert through Behavioural Cloning for both [FrankaKitchen](https://robotics.farama.org/envs/franka_kitchen/franka_kitchen/) and [reacher](https://gymnasium.farama.org/environments/mujoco/reacher/) environments. You should set:\n",
    "### Training Hyperparameters\n",
    "- `seed`: For reproducibility of training runs\n",
    "- `batch_size`: Number of samples state-action per batch\n",
    "- `lr`: Learning rate for the optimizer\n",
    "- `num_epochs`: Number of training epochs\n",
    "\n",
    "### Environment\n",
    "- `env_mode`: Select in which environment to train the Expert (`\"kitchen\"` or `\"reacher\"`)\n",
    "- `reacher_dataset_type`: Quality of teacher demonstrations to use for Behavioural Cloning if Reacher is the selected environment (`\"expert\"` or `\"medium\"`)\n",
    "- `filter`: If True, Reacher episodes with average reward below -0.1 will be removed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25864eca",
   "metadata": {
    "id": "25864eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'DAgger4Robotics'...\n",
      "remote: Enumerating objects: 918, done.\u001b[K\n",
      "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
      "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
      "remote: Total 918 (delta 87), reused 29 (delta 9), pack-reused 768 (from 1)\u001b[K\n",
      "Receiving objects: 100% (918/918), 163.53 MiB | 12.30 MiB/s, done.\n",
      "Resolving deltas: 100% (365/365), done.\n",
      "\u001b[33mWARNING: typer 0.16.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDAgger4Robotics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mNetworkInterface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NetworkInterface\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDAgger4Robotics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmyDatasetClass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m myDatasetClass\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDAgger4Robotics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDAgger4Robotics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtest\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m test\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDAgger4Robotics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocess_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocess_dataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DAgger4Robotics/DAgger4Robotics/training/train.py:4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDAgger4Robotics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mone_epoch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m one_epoch\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mDAgger4Robotics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcalculate_metrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m calculate_metrics\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain\u001b[39m(train_loader, val_loader, model, optimizer, loss_fn, num_epochs, device):\n\u001b[32m      8\u001b[39m   epoch_loss = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DAgger4Robotics/DAgger4Robotics/utils/calculate_metrics.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m root_mean_squared_error, mean_absolute_error, r2_score\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_metrics\u001b[39m(y_true_list, y_pred_list, metrics):\n\u001b[32m      5\u001b[39m     rmse = root_mean_squared_error(y_true=y_true_list, y_pred=y_pred_list)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#@title Parameters and Import\n",
    "\n",
    "import shutil\n",
    "shutil.rmtree('DAgger4Robotics', ignore_errors=True)\n",
    "!pip install gymnasium-robotics -q #Needed for Simulator\n",
    "!pip install pyvirtualdisplay imageio -q\n",
    "!git clone \"https://github.com/cybernetic-m/DAgger4Robotics.git\"\n",
    "!pip install \"minari[all]\" -q\n",
    "\n",
    "import minari # needed for dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from DAgger4Robotics.model.NetworkInterface import NetworkInterface\n",
    "from DAgger4Robotics.dataset.myDatasetClass import myDatasetClass\n",
    "from DAgger4Robotics.training.train import train\n",
    "from DAgger4Robotics.test.test import test\n",
    "from DAgger4Robotics.utils.preprocess_dataset import preprocess_dataset\n",
    "from DAgger4Robotics.simulator.Simulator import Simulator\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reproducibility instructions\n",
    "seed=42 #@param {type:\"integer\"}\n",
    "np.random.seed(seed)                   # NumPy\n",
    "torch.manual_seed(seed)                # PyTorch CPU\n",
    "torch.cuda.manual_seed(seed)           # PyTorch GPU\n",
    "torch.cuda.manual_seed_all(seed)       # All GPUs\n",
    "\n",
    "torch.backends.cudnn.deterministic = True   # Deterministic behaviour\n",
    "torch.backends.cudnn.benchmark = False      # Avoid non-deterministic optimizations\n",
    "\n",
    "# Hyperparameters for the training\n",
    "batch_size = 64 # @param {\"type\":\"integer\"}\n",
    "lr = 1e-3  #@param {type:\"number\"}    # Trial: 1e-3, 1e-2, 1e-4, 1e-1\n",
    "num_epochs = 50 #@param {type:\"integer\"}\n",
    "\n",
    "# Selected environment\n",
    "env_mode = 'kitchen' #@param [\"kitchen\",\"reacher\"]\n",
    "\n",
    "# Dimensions of the problem\n",
    "if env_mode == 'reacher':\n",
    "  state_dim = 10\n",
    "  action_dim = 2\n",
    "elif env_mode == 'kitchen':\n",
    "  state_dim = 20\n",
    "  action_dim = 9\n",
    "else:\n",
    "  raise ValueError('Invalid environment name. Choose between [\"reacher\",\"kitchen\"]')\n",
    "\n",
    "# Type of Franka-kitchen dataset from which we will extract approximately the first 50â€“60 steps (that contains only the microwave task)\n",
    "kitchen_dataset_type= \"complete\"\n",
    "\n",
    "# Choose the type of teacher demonstrations to load and use for behavioural cloning: performed by a \"medium\" or \"expert\" policy\n",
    "reacher_dataset_type = \"expert\" #@param [\"expert\",\"medium\"]\n",
    "\n",
    "# Filter that eliminates Reacher episodes with mean reward lower than -0.1\n",
    "filter = False #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CFAJqTlEh4PM",
   "metadata": {
    "id": "CFAJqTlEh4PM"
   },
   "source": [
    "### Dataset loading and preprocession\n",
    "- Downloads the appropriate dataset (with optional filtering for Reacher)\n",
    "- Splits it into train, validation, and test sets with a 0.7/0.2/0.1 ratio\n",
    "- Loads the splits using PyTorch `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e16d9",
   "metadata": {
    "id": "eb9e16d9"
   },
   "outputs": [],
   "source": [
    "if env_mode == 'kitchen':\n",
    "  dataset = minari.load_dataset(f'D4RL/kitchen/{kitchen_dataset_type}-v2',download=True)\n",
    "  dataset.set_seed(seed)  # Set a seed for reproducibility\n",
    "  print(\"Dataset loaded successfully!\")\n",
    "  print(f'Total Episodes: {dataset.total_episodes}')\n",
    "\n",
    "elif env_mode == 'reacher':\n",
    "  dataset = minari.load_dataset(f'mujoco/reacher/{reacher_dataset_type}-v0',download=True)\n",
    "  dataset.set_seed(seed)  # Set a seed for reproducibility\n",
    "  print(\"Dataset loaded successfully!\")\n",
    "  print(f'Total Episodes: {dataset.total_episodes}')\n",
    "\n",
    "  # Filter the dataset taking only episodes with mean reward greater then -0.1 (the mean reward is approximately between [-0.2, 0])\n",
    "  if filter:\n",
    "    filtered_dataset = dataset.filter_episodes(lambda episode: episode.rewards.mean() > -0.1)\n",
    "    print(f'Total Episodes filtered dataset: {filtered_dataset.total_episodes}')\n",
    "\n",
    "# Split the dataset into training, evaluation and test sets with percentage sizes 0.7, 0.2, 0.1\n",
    "if filter:\n",
    "  dataset_split = minari.split_dataset(filtered_dataset, sizes=[round(0.7*filtered_dataset.total_episodes), round(0.2*filtered_dataset.total_episodes), round(0.1*filtered_dataset.total_episodes)], seed=seed)\n",
    "else:\n",
    "  dataset_split = minari.split_dataset(dataset, sizes=[round(0.7*dataset.total_episodes), round(0.2*dataset.total_episodes), round(0.1*dataset.total_episodes)], seed=seed)\n",
    "\n",
    "# Taking training, test and val splits\n",
    "training_dataset = dataset_split[0]\n",
    "validation_dataset = dataset_split[1]\n",
    "test_dataset = dataset_split[2]\n",
    "print(f\"Training episodes: {len(training_dataset)}\")\n",
    "print(f\"Validation episodes: {len(validation_dataset)}\")\n",
    "print(f\"Test episodes: {len(test_dataset)}\")\n",
    "\n",
    "if env_mode=='kitchen':\n",
    "  training_dataset = preprocess_dataset(training_dataset)\n",
    "  validation_dataset = preprocess_dataset(validation_dataset)\n",
    "  test_dataset = preprocess_dataset(test_dataset)\n",
    "\n",
    "\n",
    "train_dataset_class= myDatasetClass(training_dataset, env_mode)\n",
    "print(f\"Training number of (state,action) pairs: {len(train_dataset_class)}\")\n",
    "train_loader=DataLoader(dataset=train_dataset_class, batch_size=batch_size, shuffle=True)\n",
    "test_dataset_class= myDatasetClass(test_dataset, env_mode)\n",
    "print(f\"Test number of (state,action) pairs: {len(test_dataset_class)}\")\n",
    "test_loader=DataLoader(dataset=test_dataset_class, batch_size=batch_size, shuffle=True)\n",
    "validation_dataset_class= myDatasetClass(validation_dataset, env_mode)\n",
    "print(f\"Validation number of (state,action) pairs: {len(validation_dataset_class)}\")\n",
    "val_loader=DataLoader(dataset=validation_dataset_class, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hQ1zRHjOnkvP",
   "metadata": {
    "id": "hQ1zRHjOnkvP"
   },
   "source": [
    "### Train process\n",
    "- Select the type of network to train\n",
    "- Run the train loop\n",
    "- The model with best loss on validation set will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "svFv5jYtql2E",
   "metadata": {
    "id": "svFv5jYtql2E"
   },
   "outputs": [],
   "source": [
    "#Select the network to be used for the teacher/expert. It can be 'simple' or 'deep'\n",
    "expert_type='deep' #@param [\"simple\",\"deep\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r5mywKIIJftd",
   "metadata": {
    "id": "r5mywKIIJftd"
   },
   "outputs": [],
   "source": [
    "net_wrapper = NetworkInterface(net_type=expert_type,input_dim=state_dim,output_dim=action_dim)\n",
    "net_wrapper.summary()\n",
    "model = net_wrapper.get_model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "train(\n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    loss_fn = loss_fn,\n",
    "    num_epochs = num_epochs,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cXRtc3fLoYhW",
   "metadata": {
    "id": "cXRtc3fLoYhW"
   },
   "source": [
    "### Test process\n",
    "- Select the newly trained network\n",
    "- Evaluate its performances on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sbd5aCDjGGdH",
   "metadata": {
    "id": "Sbd5aCDjGGdH"
   },
   "outputs": [],
   "source": [
    "model_path = '/content/expert_policy.pt'\n",
    "\n",
    "net_wrapper = NetworkInterface(net_type=expert_type,input_dim=state_dim,output_dim=action_dim)\n",
    "model = net_wrapper.get_model().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "model.load_state_dict(torch.load(model_path,map_location=device))\n",
    "# Testing the new teacher/expert on the test dataset\n",
    "test(\n",
    "    model = model,\n",
    "    test_dataloader = test_loader,\n",
    "    loss_fn = loss_fn,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uQJCscv6qldl",
   "metadata": {
    "id": "uQJCscv6qldl"
   },
   "source": [
    "### Simulation\n",
    "Use this section to run rollouts in the environment using the newly trained network. You can customize the simulation with the following parameters:\n",
    "- `render`: If True, displays on screen the rollouts. **Requires a GPU**\n",
    "- `framerate_per_episode` : Controls how frequently frames are rendered. Only frames where `(frame_idx % framerate_per_episode == 0)` are shown\n",
    "- `video_saving`: If True, saves the video of the episodes in `./new_videos` folder. In **Kitchen** environment, this critically increase computational time\n",
    "- `n_episodes`: Number of episodes to simulate\n",
    "- `robot_noise`: Magnitude of noise added to the robotâ€™s proprioceptive variables (only for the **Kitchen** environment)\n",
    "\n",
    "At the end of all the Rollouts, a mean_rewards.json file will be saved, and it will contain:\n",
    "- The mean rewards for each episode\n",
    "- `mean_of_means`: The overall mean reward across all episodes\n",
    "\n",
    "### Using a Saved model\n",
    "\n",
    "If you want to simulate one of our pretrained models, you can load it manually by changing:\n",
    "- `env_type`: Specifies which environment the model is intended for (`\"reacher\"` or `\"kitchen\"`)\n",
    "- `path_to_model`: Insert here the complete path to the model provided by `Dagger4Robotics` folder\n",
    "- `net_type`: The architecture type of the loaded model (`\"simple\"` or `\"deep\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vHvF-T3fkoth",
   "metadata": {
    "id": "vHvF-T3fkoth"
   },
   "outputs": [],
   "source": [
    "#@title Parameters of the experiments { run: \"auto\" }\n",
    "render = True #@param {type:\"boolean\"}\n",
    "framerate_per_episode=5  #@param {type:\"integer\"}\n",
    "video_saving = False #@param {type:\"boolean\"}\n",
    "n_episodes = 1 #@param {type:\"integer\"}\n",
    "robot_noise=0.1 #@param {type:\"number\"}\n",
    "env_type = env_mode\n",
    "\n",
    "path_to_model='/content/expert_policy.pt'\n",
    "net_type=expert_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beNKJZG5kszZ",
   "metadata": {
    "id": "beNKJZG5kszZ"
   },
   "outputs": [],
   "source": [
    "sim = Simulator(\n",
    "        env_mode=env_mode,\n",
    "        net_type=net_type,\n",
    "        path_to_model=path_to_model,\n",
    "        n_episodes=n_episodes,\n",
    "        render=render,\n",
    "        framerate_per_episode=framerate_per_episode,\n",
    "        video_saving=video_saving,\n",
    "        robot_noise=robot_noise, #Only useful for Franka-Kitchen\n",
    "        device=device\n",
    "    )\n",
    "sim.run()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
